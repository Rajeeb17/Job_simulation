# -*- coding: utf-8 -*-
"""Task4_Bucket_FICOscores

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11yqqeW7yogCoyeqrnVwWpKf91w-FTkpa
"""

import pandas as pd
import numpy as np

df = pd.read_csv("Task 3 and 4_Loan_Data .csv")

# Required columns
fico = df["fico_score"].values
default = df["default"].values

# Sort by FICO (important for monotonic buckets)
order = np.argsort(fico)
fico = fico[order]
default = default[order]

def bucket_log_likelihood(k, n):
    """
    Log-likelihood contribution of one bucket.
    """
    if k == 0 or k == n:
        return 0.0  # avoid log(0)
    p = k / n
    return k * np.log(p) + (n - k) * np.log(1 - p)

N = len(fico)

# Prefix sums for fast counts
cum_defaults = np.cumsum(default)
cum_total = np.arange(1, N + 1)

def get_bucket_stats(i, j):
    """
    Bucket covering indices [i, j)
    """
    n = j - i
    k = cum_defaults[j - 1] - (cum_defaults[i - 1] if i > 0 else 0)
    return k, n

def optimal_fico_buckets(num_buckets):
    """
    Returns optimal bucket boundaries using log-likelihood maximization.
    """
    dp = np.full((num_buckets + 1, N + 1), -np.inf)
    split = np.zeros((num_buckets + 1, N + 1), dtype=int)

    dp[0, 0] = 0

    for b in range(1, num_buckets + 1):
        for j in range(1, N + 1):
            for i in range(b - 1, j):
                k, n = get_bucket_stats(i, j)
                ll = bucket_log_likelihood(k, n)
                val = dp[b - 1, i] + ll
                if val > dp[b, j]:
                    dp[b, j] = val
                    split[b, j] = i

    # Recover boundaries
    boundaries = []
    j = N
    for b in range(num_buckets, 0, -1):
        i = split[b, j]
        boundaries.append((i, j))
        j = i

    boundaries.reverse()
    return boundaries

def build_rating_map(num_buckets):
    boundaries = optimal_fico_buckets(num_buckets)

    rating_map = []
    for rating, (i, j) in enumerate(boundaries, start=1):
        rating_map.append({
            "rating": rating,
            "fico_min": fico[i],
            "fico_max": fico[j - 1],
            "defaults": int(default[i:j].sum()),
            "total": j - i,
            "pd": default[i:j].mean()
        })

    # Reverse so lower rating = better credit
    rating_map = sorted(rating_map, key=lambda x: -x["fico_min"])

    for idx, r in enumerate(rating_map, start=1):
        r["rating"] = idx

    return pd.DataFrame(rating_map)

rating_table = build_rating_map(num_buckets=10)
print(rating_table)

